{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "effbf36a-4fb2-41c7-a7fa-0101afe6e211",
   "metadata": {},
   "source": [
    "# LangChain Playground #1\n",
    "\n",
    "At its core, LangChain is framework built around LLMs. We have use it to build chatbots, generative question-answering, summarization, and much more.\n",
    "\n",
    "The core idea of the library is that we can \"chain\" together different components to create more advanced use cases around LLMs. Chain may consist of multiple components from several modules: Prompt Templates, LLMs, Agents, and Memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7f433c-6412-42c1-a567-799220e5fc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c023a5e",
   "metadata": {},
   "source": [
    "## Using LLMs in LangChain\n",
    "LangChain support several LLM providers, like HuggingFace and OpenAI.\n",
    "Let's exmplore the different LLM integrations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ec3fb7e",
   "metadata": {},
   "source": [
    "### HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc73545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a6b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"HF_API_TOKEN_GOES_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353fc54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c05525d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7755bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
