{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "effbf36a-4fb2-41c7-a7fa-0101afe6e211",
   "metadata": {},
   "source": [
    "# LangChain Playground #0\n",
    "\n",
    "LangChain end-to-end walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f38581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain\n",
    "%pip install -qU openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c023a5e",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Using LangChain will usually require integrations with one or more model providers, data stores, apis, etc.\n",
    "For this example, we will be using OpenAI’s APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a6b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"KEY_GOES_HERE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "786257a5",
   "metadata": {},
   "source": [
    "## Building a Language Model Application\n",
    "Now that we have installed LangChain and set up our environment, we can start building our language model application.\n",
    "\n",
    "LangChain provides many modules that can be used to build language model applications. Modules can be combined to create more complex applications, or be used individually for simple applications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41da8a3b",
   "metadata": {},
   "source": [
    "### LLM: Get predictions from a LLM model\n",
    "\n",
    "The most basic building block of LangChain is calling an LLM on some input. Let’s walk through a simple example of how to do this. For this purpose, let’s pretend we are building a service that generates a company name based on what the company makes.\n",
    "\n",
    "In order to do this, we first need to import the LLM wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bbce979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "032978ec",
   "metadata": {},
   "source": [
    "We can then initialize the wrapper with any arguments. In this example, we probably want the outputs to be MORE random, so we’ll initialize it with a HIGH temperature.\n",
    "\n",
    "We will use OpenAI's text-davinci-003. This is at the momemnt the capable in the GPT series. Can do any task the other models can do, often with higher quality, longer output and better instruction-following. Also supports inserting completions within text. Max number of tokens is 4,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9a5ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9, model_name=\"text-davinci-003\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b0eb100",
   "metadata": {},
   "source": [
    "We can now call it on some input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15ccf3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Vivid Sockery.\n"
     ]
    }
   ],
   "source": [
    "text = \"What would be a good company name a company that makes colorful socks?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818215f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
